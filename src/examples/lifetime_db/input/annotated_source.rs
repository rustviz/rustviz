fn main() {
    // requests, resources generated by main thread
    let mut available_resource: u32 = 60;
    let mut request_queue: VecDeque<&mut Request> = VecDeque::new();
    let reads_cnt: u32 = 20;
    let mut RD_rq: Request = Request::new(reads_cnt, RequestType::READ);
    request_queue.push_back(<tspan data-hash="2">&mut RD_rq</tspan>);
    let updates_cnt: u32 = 30;
    let mut UD_rq: Request = Request::new(updates_cnt, RequestType::UPDATE);
    request_queue.push_back(<tspan data-hash="3">&mut UD_rq</tspan>);
    let deletes_cnt: u32 =50;
    let mut DL_rq: Request = Request::new(deletes_cnt, RequestType::DELETE);
    request_queue.push_back(<tspan data-hash="4">&mut DL_rq</tspan>);
    // ..., process requests in multi-threading way ...
    // this might be another thread that deal with request processing ...
    let <tspan data-hash="5">ptr_to_resource</tspan> = &mut available_resource;
    let <tspan data-hash="6">request_halfway</tspan> = process_requests(<tspan data-hash="1">&mut request_queue</tspan>, <tspan data-hash="5">ptr_to_resource</tspan>);
    if let Some(req) = <tspan data-hash="6">request_halfway</tspan> {
        println!("#{} of {} requests are left unprocessed!", req.num_request_left, req.request_type.to_string());
    }
    println!("there are #{} free resource left.", available_resource);
}

fn process_requests<'i,'a>(queue: &'i mut VecDeque<&'i mut Request<'i>>, max_process_unit: &'a mut u32) -> Option<&'i mut Request<'i>>{
    loop {
        let front_request: Option<&mut Request> = queue.pop_front();
        if let Some(request) = front_request{
            // if current max_process_unit is greater than current requests
            if request.num_request_left <= max_process_unit{
                println!("Served #{} of {} requests.", request.num_request_left, request.request_type.to_string());
                // decrement the amount of resource spent on this request
                *max_process_unit = *max_process_unit - *request.num_request_left;
                // signify this request has been processed
                *request.num_request_left = 0;
            }
            // not enough
            else{
                // process as much as we can
                *request.num_request_left = *request.num_request_left - *max_process_unit;
                // sad, no free resource anymore
                *max_process_unit = 0;
                // enqueue the front request back to queue, hoping someone will handle it...
                // queue.push_front(request);
                return Option::Some(request);
            }
            //
        }
        else {
            // no available request to process, ooh-yeah!
            return Option::None;

        }
    }
}

